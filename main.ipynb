{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import dataset\n",
    "import evaluate\n",
    "import models\n",
    "import torch.utils.data as data\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rating = 'Data/ml-1m.train.rating'\n",
    "test_negative = 'Data/ml-1m.test.negative'\n",
    "train_data, test_data, user_num ,item_num, train_mat = dataset.load_data(train_rating, test_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ng = 4\n",
    "batch_size = 256\n",
    "epochs = 20\n",
    "top_k = 10\n",
    "out = True\n",
    "model_path = './models/'\n",
    "model_type = 'mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.Data(\n",
    "\t\ttrain_data, item_num, train_mat, num_ng, True)\n",
    "test_dataset = dataset.Data(\n",
    "\t\ttest_data, item_num, train_mat, 0, False)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "\t\tbatch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = data.DataLoader(test_dataset,\n",
    "\t\tbatch_size=100, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers_config(number_hidden_layers, predictive_factor):\n",
    "  layers = []\n",
    "  for i in range(number_hidden_layers):\n",
    "    layers.append(predictive_factor)\n",
    "    predictive_factor = predictive_factor * 2\n",
    "  layers.reverse()\n",
    "  return layers[0]//2, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, [256, 128, 64, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictive_factor = 32\n",
    "number_hidden_layers = 4\n",
    "embedding_dim, layers = get_layers_config(number_hidden_layers, predictive_factor)\n",
    "embedding_dim, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.MLP(user_num, item_num, embedding_dim, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, best_hr = 0, 0\n",
    "for epoch in range(epochs):\n",
    "\tmodel.train() # Enable dropout (if have).\n",
    "\tstart_time = time.time()\n",
    "\ttrain_loader.dataset.ng_sample()\n",
    "\n",
    "\tfor user, item, label in train_loader:\n",
    "\t\tuser = user.to(device)\n",
    "\t\titem = item.to(device)\n",
    "\t\tlabel = label.float().to(device)\n",
    "\n",
    "\t\tmodel.zero_grad()\n",
    "\t\tprediction = model(user, item)\n",
    "\t\tloss = loss_function(prediction, label)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t# writer.add_scalar('data/loss', loss.item(), count)\n",
    "\t\tcount += 1\n",
    "\n",
    "\tmodel.eval()\n",
    "\tHR, NDCG = evaluate.metrics(model, test_loader, top_k)\n",
    "\n",
    "\telapsed_time = time.time() - start_time\n",
    "\tprint(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + \n",
    "\t\t\ttime.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "\tprint(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
    "\n",
    "\tif HR > best_hr:\n",
    "\t\tbest_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
    "\t\tif out:\n",
    "\t\t\tif not os.path.exists(model_path):\n",
    "\t\t\t\tos.mkdir(model_path)\n",
    "\t\t\ttorch.save(model, \n",
    "\t\t\t\t'{}{}.pth'.format(model_path, model_type))\n",
    "\n",
    "print(\"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n",
    "\t\t\t\t\t\t\t\t\tbest_epoch, best_hr, best_ndcg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7856f28a8102bce8e6ec63541b338d68bfbcc129f3f07cda64ee304fa0e68c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
